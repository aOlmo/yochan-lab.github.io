<!DOCTYPE html>

<html lang="en">

    <head>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

        <link rel="icon" href="../favicon.ico">

        <title>Yochan @ AAAI 2019</title>

        <!-- Bootstrap core CSS -->
        <link href="../ASSETS/bootstrap-4.0.0/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom styles for this template -->
        <link href="./files/css/custom.css" rel="stylesheet">

        <!-- jQuery -->
        <script src="../ASSETS/jquery/jquery-3.2.1.min.js"></script>

        <!-- Bootstrap core JavaScript
        ================================================== -->
        <script src="../ASSETS/bootstrap-4.0.0/js/popper.min.js"></script>
        <script src="../ASSETS/bootstrap-4.0.0/js/bootstrap.min.js"></script>

        <!-- Custom JavaScript -->
        <script src="./files/js/custom.js"></script>

    </head>

    <body class="bg-light" id="body" data-spy="scroll" data-target="#body" data-offset="100">

        <nav class="navbar navbar-expand-md fixed-top navbar-dark bg-dark">
            <a class="navbar-brand spy-enabled" href="#body"><strong>Yochan @ AAAI 2019</strong></a>
        </nav>

        <div class="nav-scroller bg-white box-shadow">
            <nav class="nav nav-underline">
                <a class="nav-link bold" href="http://rakaposhi.eas.asu.edu/yochan/">Home</a>
                <a class="nav-link bold" href="https://robotics.asu.edu/">ASU</a>
                <a class="nav-link bold" href="http://www.ae-robots.com/">&AElig;Robotics</a>
                <a class="nav-link nav-link-no-link d-none d-sm-block">Last Updated <span class="badge badge-pill bg-light align-text-bottom">2019-01-26</span></a>
            </nav>
        </div>

        <main role="main" class="container">

        <div class="d-flex align-items-center p-3 my-3 text-white-50 bg-maroon rounded box-shadow">
            <img class="mr-3" src="./files/images/icon.png" width="48" height="48" style="border-radius: 3pt;">
            <img class="mr-3" src="./files/images/rao.png" width="48" height="48" style="border-radius: 3pt;">
            <div class="lh-100">
                <h6 class="mb-0 text-white lh-100">Yochan Lab | Arizona State University</h6>
                <small>PI: Subbarao Kambhampati | <a class="nav-link-yellow text-white-50" href="mailto:rao@asu.edu">rao@asu.edu</a> | <a class="nav-link-yellow text-white-50" href="https://twitter.com/rao2z">@rao2z</a> | <a class="nav-link-yellow text-white-50" href="http://rakaposhi.eas.asu.edu/">rakaposhi.eas.asu.edu</a> </small>
            </div>
        </div>

<div class="my-3 p-3 bg-white rounded box-shadow" id="AAAI-2019">

<h6 class="border-bottom border-gray pb-2 mb-0">AAAI 2019</h6>

<div id="AAAI-2019">

<div id="accordion-AAAI-2019" role="tablist">

<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-1-AAAI-2019" aria-expanded="false" aria-controls="collapse-1-AAAI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">Markov Game Modeling of Moving Target Defense for Strategic Detection of Threats in Cloud Networks</strong>
</div>
<span class="d-block">Ankur Chowdhary*, Sailik Sengupta*, Dijiang Huang, Subbarao Kambhampati</span>
<br>
<span class="d-block"><em>AICS Workshop (oral) on Sunday 1/27/2019 9:45 - 10:00</em></span>
<a class="paper-link text-right badge badge-success" href="https://arxiv.org/abs/1812.09660" target="_blank">Paper Link</a>

</div>

</div>

<div id="collapse-1-AAAI-2019" class="collapse" role="tabpanel" data-parent="#accordion-AAAI-2019">
<div class="card-body">
<p style="color:black;">
<strong>Abstract:</strong> The processing and storage of critical data in large-scale cloud networks necessitate the need for scalable security solutions. It has been shown that deploying all possible security measures incurs a cost on performance by using up valuable computing and networking resources which are the primary selling points for cloud service providers. Thus, there has been a recent interest in developing Moving Target Defense (MTD) mechanisms that helps one optimize the joint objective of maximizing security while ensuring that the impact on performance is minimized. Often, these techniques model the problem of multi-stage attacks by stealthy adversaries as a single-step attack detection game using graph connectivity measures as a heuristic to measure performance, thereby (1) losing out on valuable information that is inherently present in graph-theoretic models designed for large cloud networks, and (2) coming up with certain strategies that have asymmetric impacts on performance. In this work, we leverage knowledge in attack graphs of a cloud network in formulating a zero-sum Markov Game and use the Common Vulnerability Scoring System (CVSS) to come up with meaningful utility values for this game. Then, we show that the optimal strategy of placing detecting mechanisms against an adversary is equivalent to computing the mixed Min-max Equilibrium of the Markov Game. We compare the gains obtained by using our method to other techniques presently used in cloud network security, thereby showing its effectiveness. Finally, we highlight how the method was used for a small real-world cloud system.
</p>
</div>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-2-AAAI-2019" aria-expanded="false" aria-controls="collapse-2-AAAI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">(When) Can AI Bots Lie?</strong>
</div>
<span class="d-block">Tathagata Chakraborti and Subbarao Kambhampati</span>
<br>
<span class="d-block"><em>AIES: Sunday 1/27/19 9:50 (Lightning Talk) and 10:00-10:30 (Poster)</em></span>
<a class="paper-link text-right badge badge-success" href="https://yochan-lab.github.io/papers/files/papers/aies19-greater-good.pdf" target="_blank">Paper Link</a>
<a class="paper-link text-right badge badge-warning" href="https://www.zdnet.com/article/should-ai-bots-lie/" target="_blank">ZDNet</a>
<a class="paper-link text-right badge badge-warning" href="https://www.acm.org/media-center/2019/january/aies-2019" target="_blank">ACM News</a>

</div>

</div>

<div id="collapse-2-AAAI-2019" class="collapse" role="tabpanel" data-parent="#accordion-AAAI-2019">
<div class="card-body">
<p style="color:black;">
<strong>Abstract:</strong> The ability of an AI agent to build mental models can open up pathways for manipulating and exploiting the human in the hopes of achieving some greater good. In fact, such behavior does not necessarily require any malicious intent but can rather be borne out of cooperative scenarios. It is also beyond the scope of misinterpretation of intents, as in the case of value alignment problems, and thus can be effectively engineered if desired (i.e. algorithms exist that can optimize such behavior not because models were mispecified but because they were misused). Such techniques pose several unresolved ethical and moral questions with regards to the design of autonomy. In this paper, we illustrate some of these issues in a teaming scenario and investigate how they are perceived by participants in a thought experiment. Finally, we end with a discussion on the moral implications of such behavior from the perspective of the doctor-patient relationship.
</p>
</div>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-3-AAAI-2019" aria-expanded="false" aria-controls="collapse-3-AAAI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">Zoo of Interpretable Behavior</strong>
</div>
<span class="d-block">David E. Smith (joint work with with Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreedharan, and Subbarao Kambhampati)</span>
<br>
<span class="d-block"><em>Invited Talk at PAIR Workshop (Monday) 1/28/19 4:00-4:45</em></span>
<a class="paper-link text-right badge badge-success" href="https://arxiv.org/abs/1811.09722" target="_blank">Paper Link</a>

</div>

</div>

<div id="collapse-3-AAAI-2019" class="collapse" role="tabpanel" data-parent="#accordion-AAAI-2019">
<div class="card-body">
<p style="color:black;">
<strong>Abstract:</strong> There has been increasing interest in the generation of behavior that is "understandable" or "interpretable" by an observer. In the Robotics and Planning communities, various notions have been introduced and investigated, including Explicability, Legibility, Predictability, Transparency, Privacy, Security, and Obfuscation. Not surprisingly, many of these notions are also related to goal and plan recognition. However, it is not always clear exactly how these notions relate to each other, or what assumptions are being made about the domain model and computational capabilities of the agent and observer. In this talk, I will attempt to impose some order on this zoo, by presenting a formal taxonomy of different forms of interpretability and un-interpretability. I will also point out some interesting variations and combinations that have not yet been considered or explored.
</p>
</div>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-4-AAAI-2019" aria-expanded="false" aria-controls="collapse-4-AAAI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">Plan-Recognition-Driven Attention Modeling for Visual Recognition</strong>
</div>
<span class="d-block">Yantian Zha, Yikang Li, Tianshu Yu, Subbarao Kambhampati, Baoxin Li</span>
<br>
<span class="d-block"><em>PAIR Workshop (oral) on Monday 1/28/2019 3:00 - 3:15 and poster 3:45 - 4:00</em></span>
<a class="paper-link text-right badge badge-success" href="https://arxiv.org/abs/1812.00301" target="_blank">Paper Link</a>

</div>

</div>

<div id="collapse-4-AAAI-2019" class="collapse" role="tabpanel" data-parent="#accordion-AAAI-2019">
<div class="card-body">
<p style="color:black;">
<strong>Abstract:</strong> Human visual recognition of activities or external agents involves an interplay between high-level plan recognition and low-level perception. Given that, a natural question to ask is: can low-level perception be improved by high-level plan recognition? We formulate the problem of leveraging recognized plans to generate better top-down attention maps \cite{gazzaniga2009,baluch2011} to improve the perception performance. We call these top-down attention maps specifically as plan-recognition-driven attention maps. To address this problem, we introduce the Pixel Dynamics Network. Pixel Dynamics Network serves as an observation model, which predicts next states of object points at each pixel location given observation of pixels and pixel-level action feature. This is like internally learning a pixel-level dynamics model. Pixel Dynamics Network is a kind of Convolutional Neural Network (ConvNet), with specially-designed architecture. Therefore, Pixel Dynamics Network could take the advantage of parallel computation of ConvNets, while learning the pixel-level dynamics model. We further prove the equivalence between Pixel Dynamics Network as an observation model, and the belief update in partially observable Markov decision process (POMDP) framework. We evaluate our Pixel Dynamics Network in event recognition tasks. We build an event recognition system, ER-PRN, which takes Pixel Dynamics Network as a subroutine, to recognize events based on observations augmented by plan-recognition-driven attention.
</p>
</div>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-5-AAAI-2019" aria-expanded="false" aria-controls="collapse-5-AAAI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">A Unified Framework for Planning in Adversarial and Cooperative Environments</strong>
</div>
<span class="d-block">Anagha Kulkarni, Siddharth Srivastava and Subbarao Kambhampati</span>
<br>
<span class="d-block"><em>AAAI Technical session (oral) on Thursday 1/31/2019 2:00 - 3:30 and poster on Wednesday 1/30/2019

PAIR Workshop (oral) on Monday 1/28/2019 4:45 - 5:00 and poster 3:45 - 4:00</em></span>
<a class="paper-link text-right badge badge-success" href="https://yochan-lab.github.io/papers/files/papers/anagha-aaai-2019.pdf" target="_blank">Paper Link</a>

</div>

</div>

<div id="collapse-5-AAAI-2019" class="collapse" role="tabpanel" data-parent="#accordion-AAAI-2019">
<div class="card-body">
<p style="color:black;">
<strong>Abstract:</strong> Users of AI systems may rely upon them to produce plans for
achieving desired objectives. Such AI systems should be able
to compute obfuscated plans whose execution in adversarial
situations protects privacy, as well as legible plans which are
easy for team members to understand in cooperative situations. We develop a unified framework that addresses these
dual problems by computing plans with a desired level of
comprehensibility from the point of view of a partially informed observer. For adversarial settings, our approach produces obfuscated plans with observations that are consistent
with at least k goals from a set of decoy goals. By slightly
varying our framework, we present an approach for producing legible plans in cooperative settings such that the observation sequence projected by the plan is consistent with at
most j goals from a set of confounding goals. In addition, we
show how the observability of the observer can be controlled
to either obfuscate or convey the actions in a plan when the
goal is known to the observer. We present theoretical results
on the complexity analysis of our approach. We also present
an empirical evaluation to show the feasibility and usefulness
of our approaches using IPC domains.
</p>
</div>
</div>

</div>


</div>

</div>

</div>


        </main>

        <div class="footer-container">

            <div class="footer-bottom-left" style="width:100%;">

                <hr>

                <footer class="text-center" style="color:gray;">
                    <p>&copy; Yochan</p>
                </footer>

            </div>

        </div>

    </body>

</html>