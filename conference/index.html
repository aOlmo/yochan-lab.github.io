<!DOCTYPE html>

<html lang="en">

    <head>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

        <link rel="icon" href="../favicon.ico">

        <title>Yochan @ HRI 2019</title>

        <!-- Bootstrap core CSS -->
        <link href="../ASSETS/bootstrap-4.0.0/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom styles for this template -->
        <link href="./files/css/custom.css" rel="stylesheet">

        <!-- jQuery -->
        <script src="../ASSETS/jquery/jquery-3.2.1.min.js"></script>

        <!-- Bootstrap core JavaScript
        ================================================== -->
        <script src="../ASSETS/bootstrap-4.0.0/js/popper.min.js"></script>
        <script src="../ASSETS/bootstrap-4.0.0/js/bootstrap.min.js"></script>

        <!-- Custom JavaScript -->
        <script src="./files/js/custom.js"></script>

    </head>

    <body class="bg-light" id="body" data-spy="scroll" data-target="#body" data-offset="100">

        <nav class="navbar navbar-expand-md fixed-top navbar-dark bg-dark">
            <a class="navbar-brand spy-enabled" href="#body"><strong>Yochan @ HRI 2019</strong></a>
        </nav>

        <div class="nav-scroller bg-white box-shadow">
            <nav class="nav nav-underline">
                <a class="nav-link bold" href="http://rakaposhi.eas.asu.edu/yochan/">Home</a>
                <a class="nav-link bold" href="https://robotics.asu.edu/">ASU</a>
                <a class="nav-link bold" href="http://www.ae-robots.com/">&AElig;Robotics</a>
                <a class="nav-link nav-link-no-link d-none d-sm-block">Last Updated <span class="badge badge-pill bg-light align-text-bottom">2019-03-11</span></a>
            </nav>
        </div>

        <main role="main" class="container">

        <div class="d-flex align-items-center p-3 my-3 text-white-50 bg-maroon rounded box-shadow">
            <img class="mr-3" src="./files/images/icon.png" width="48" height="48" style="border-radius: 3pt;">
            <img class="mr-3" src="./files/images/hri.png" width="auto" height="48" style="border-radius: 3pt;">
            <div class="lh-100">
                <h6 class="mb-0 text-white lh-100">Yochan Lab | Arizona State University</h6>
                <small>PI: Subbarao Kambhampati | <a class="nav-link-yellow text-white-50" href="mailto:rao@asu.edu">rao@asu.edu</a> | <a class="nav-link-yellow text-white-50" href="https://twitter.com/rao2z">@rao2z</a> | <a class="nav-link-yellow text-white-50" href="http://rakaposhi.eas.asu.edu/">rakaposhi.eas.asu.edu</a> </small>
            </div>
        </div>

<div class="my-3 p-3 bg-white rounded box-shadow" id="HRI-2019">

<h6 class="border-bottom border-gray pb-2 mb-0">HRI 2019</h6>

<div id="HRI-2019">

<div id="accordion-HRI-2019" role="tablist">

<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-1-HRI-2019" aria-expanded="false" aria-controls="collapse-1-HRI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">[Invited Talk] Planning with Multiple Models: Plan Explanations and Explicability</strong>
</div>
<span class="d-block">Tathagata Chakraborti</span>
<br>
<span class="d-block"><em>HRI 2019 Workshop Test Methods and Metrics for Effective HRI in Collaborative Human-Robot Teams: 10:50 - 11:35 am</em></span>
<a class="paper-link text-right badge badge-success" href="https://www.nist.gov/news-events/events/2019/03/test-methods-and-metrics-effective-hri-collaborative-human-robot-teams" target="_blank">Link</a>

</div>

</div>

<div id="collapse-1-HRI-2019" class="collapse" role="tabpanel" data-parent="#accordion-HRI-2019">
<div class="card-body">
<p style="color:black;">
    Effective planning with humans in the loop requires taking into account the task and mental model of the human. In this talk, I explore how this can help a robot conform to human expectations (in the form of explicable planning) and explain its behavior in terms of those expectations (via a process called model reconciliation). I will ground these behaviors in a typical search and rescue setting which I argue makes for a perfect benchmark domain to study human-robot teaming behavior in its many forms.
</p>
</div>
<hr>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-2-HRI-2019" aria-expanded="false" aria-controls="collapse-2-HRI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">[VAM-HRI 2019] 2nd International Workshop on Virtual, Augmented and Mixed Reality for Human-Robot Interaction</strong>
</div>
<span class="d-block">Tom Williams, Dan Szafir, Tathagata Chakraborti, Elizabeth Phillips</span>
<br>
<span class="d-block"><em>Monday 3/11/19 afteroon</em></span>
<a class="paper-link text-right badge badge-success" href="http://vam-hri.xyz/" target="_blank">Link</a>

</div>

</div>

<div id="collapse-2-HRI-2019" class="collapse" role="tabpanel" data-parent="#accordion-HRI-2019">
<div class="card-body">
<p style="color:black;">
    At VAM-HRI we seek to bring together HRI, Robotics, Artificial Intelligence, and Mixed Reality researchers to identify challenges in mixed reality interactions between humans and robots. VAM-HRI was held for the first time at HRI 2018, where it served as the first workshop of its kind at an academic AI or Robotics conference, and served as a timely call to arms to the academic community in response to the growing promise of this emerging field. VAM-HRI 2019 is looking to follow on the success of last year's workshop, and present new opportunities for expanding this nascent research community.
</p>
</div>
<hr>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-3-HRI-2019" aria-expanded="false" aria-controls="collapse-3-HRI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">The Reality-Virtuality Interaction Cube</strong>
</div>
<span class="d-block">Tom Williams, Dan Szafir, Tathagata Chakraborti</span>
<br>
<span class="d-block"><em>VAM-HRI 2019 Presentation: Monday 3/11/19 4:00pm + HRI 2019 Late Breaking Report: 8am onwards from 3/12/19 in Room 324</em></span>
<a class="paper-link text-right badge badge-success" href="https://yochan-lab.github.io/papers/files/papers/cube.pdf" target="_blank">Link</a>

</div>

</div>

<div id="collapse-3-HRI-2019" class="collapse" role="tabpanel" data-parent="#accordion-HRI-2019">
<div class="card-body">
<p style="color:black;">
    There has recently been an explosion of work in the humanrobot interaction (HRI) community on the use of mixed, augmented, and virtual reality. 
In this paper, we present a novel conceptual framework to characterize and cluster work in this new area and identify gaps for future research. 
We begin by introducing the Plane of Interaction: a framework for characterizing interactive technologies in a 2D space informed by the Model-View-Controller design pattern. 
We then describe how Interaction Design Elements that contribute to the interactivity of a technology can be characterized within this space and present a taxonomy of Mixed-Reality Interaction Design Elements. 
We then discuss how these elements may be rendered onto both reality- and virtuality-based environments using a variety of hardware devices and introduce the {\em Reality-Virtuality Interaction Cube}: a three-dimensional continuum representing the design space of interactive technologies formed by combining the Plane of Interaction with the Reality-Virtuality Continuum.
Finally, we demonstrate the feasibility and utility of this framework by clustering and analyzing the set of papers presented at the recent 2018 VAM-HRI Workshop.
</p>
</div>
<hr>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-4-HRI-2019" aria-expanded="false" aria-controls="collapse-4-HRI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">Towards Understanding User Preferences of Explanation Types in Model Reconciliation</strong>
</div>
<span class="d-block">Zahra Zahedi, Alberto Olmo, Tathagata Chakraborti, Sarath Sreedharan, Subbarao Kambhampati</span>
<br>
<span class="d-block"><em>HRI 2019 Late Breaking Report: 8am onwards from 3/10/19 in Room 324</em></span>
<a class="paper-link text-right badge badge-success" href="https://yochan-lab.github.io/papers/files/papers/hri-lbr-model-rec.pdf" target="_blank">Link</a>

</div>

</div>

<div id="collapse-4-HRI-2019" class="collapse" role="tabpanel" data-parent="#accordion-HRI-2019">
<div class="card-body">
<p style="color:black;">
    Recent work has formalized the explanation process
in the context of automated planning as one of model reconciliation - i.e. a process by which the planning agent can bring
the explainee's (possibly faulty) model of a planning problem
closer to its understanding of the ground truth until both agree
that its plan is the best possible. The content of explanations
can thus range from misunderstandings about the agent's beliefs
(state), desires (goals) and capabilities (action model). Though
existing literature has considered different kinds of these model
differences to be equivalent, literature on the explanations in
social sciences has suggested that explanations with similar logical
properties may often be perceived differently by humans. In
this brief report, we explore to what extent humans attribute
importance to different kinds of model differences that have been
traditionally considered equivalent in the model reconciliation
setting. Our results suggest that people prefer the explanations
which are related to the effects of actions.
</p>
</div>
<hr>
</div>

</div>
<div>

<div class="media pt-3 entry-link" data-toggle="collapse" href="#collapse-5-HRI-2019" aria-expanded="false" aria-controls="collapse-5-HRI-2019">
<div class="media-body pb-3 mb-0 small lh-125 border-bottom border-gray">
<div class="d-flex justify-content-between align-items-center w-100">
<strong class="text-gray-dark">Explanations as Model Reconciliation: An Empirical Study</strong>
</div>
<span class="d-block">Tathagata Chakraborti, Sarath Sreedharan, Sachin Grover, Subbarao Kambhampati</span>
<br>
<span class="d-block"><em>Full Paper Talk: Wednesday 3/13/19 Session 6</em></span>
<a class="paper-link text-right badge badge-success" href="https://yochan-lab.github.io/papers/files/papers/hri-model-rec.pdf" target="_blank">Link</a>

</div>

</div>

<div id="collapse-5-HRI-2019" class="collapse" role="tabpanel" data-parent="#accordion-HRI-2019">
<div class="card-body">
<p style="color:black;">
    Recent work in explanation generation for decision making agents has looked at how unexplained behavior of autonomous systems can be understood in terms of differences in the model of the system and the human's understanding of the same, and how the explanation process as a result of this mismatch can be then seen as a process of reconciliation of these models. 
Existing algorithms in such settings, while having been built on contrastive, selective and social properties of explanations as studied extensively in the psychology literature, have not, to the best of our knowledge, been evaluated in settings with actual humans in the loop. 
As such, the applicability of such explanations to human-AI and human-robot interactions remains suspect. 
In this paper, we set out to evaluate these explanation generation algorithms in a series of studies in a mock search and rescue scenario with an internal semi-autonomous robot and an external human commander.
During that process, we hope to demonstrate to what extent the properties of these algorithms hold as they are evaluated by humans.
</p>
</div>
<hr>
</div>

</div>


</div>

</div>

</div>


        </main>

        <div class="footer-container">

            <div class="footer-bottom-left" style="width:100%;">

                <hr>

                <footer class="text-center" style="color:gray;">
                    <p>&copy; Yochan</p>
                </footer>

            </div>

        </div>

    </body>

</html>